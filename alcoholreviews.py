import pandas as pd
import streamlit as st
import re
from collections import Counter

# è®¾ç½®é¡µé¢å®½åº¦å’Œæ ‡é¢˜
st.set_page_config(page_title="é…’ç²¾ç¬”å–ç‚¹æ¸—é€çœ‹æ¿", layout="wide")

# --- 0. é…ç½®è¯åº“ ---
EXTENDED_MAPPING = {
    "alcohol": ["alcohol", "permanent", "ink"],
    "markers": ["markers", "marker", "pens", "pen"],
    "colors": ["colors", "color", "shades", "pigments"],
    "coloring": ["coloring", "color in", "fill in"],
    "art": ["art", "artist", "artwork"],
    "dual": ["dual", "double", "two sided", "both ends"],
    "tip": ["tip", "tips", "nib", "point"],
    "drawing": ["drawing", "draw", "strokes"],
    "set": ["set", "kit", "pack", "bundle"],
    "marker": ["marker", "pen"],
    "kids": ["kids", "children", "child", "son", "daughter"],
    "adult": ["adult", "adults", "grown up"],
    "sketching": ["sketching", "sketch", "doodle"],
    "illustration": ["illustration", "illustrations", "illustrate"],
    "adults": ["adults", "adult", "grown ups", "coloring"],
    "chisel": ["chisel", "broad", "wide", "wedge"],
    "sketch": ["sketch", "sketching", "sketches", "doodle"],
    "artist": ["artist", "artists", "professional"],
    "fine": ["fine", "point", "small", "thin", "detail"],
    "case": ["case", "bag", "organizer", "holder", "carrying"],
    "permanent": ["permanent", "alcohol", "waterproof"],
    "brush": ["brush", "flexible", "soft", "foam"],
    "tips": ["tips", "tip", "nib", "nibs"],
    "painting": ["painting", "paint", "color"],
    "perfect": ["perfect", "great", "excellent", "ideal"],
    "pens": ["pens", "pen", "markers", "marker"],
    "double": ["double", "dual", "two ends", "both sides"],
    "refillable": ["refillable", "refills", "refill", "ink bottle"],
    "artists": ["artists", "artist", "pro", "professional"],
    "tipped": ["tipped", "tip", "ends"],
    "supplies": ["supplies", "stationary", "tools", "kit"],
    "ohuhu": ["ohuhu", "honolulu", "oahu","brand"],
    "book": ["book", "books", "coloring book", "pages"],
    "color": ["color", "colors", "shades", "palette"],
    "blender": ["blender", "blending", "mix"],
    "books": ["books", "book", "coloring books"],
    "card": ["card", "cards", "cardstock", "postcards"],
    "making": ["making", "craft", "create", "diy"],
    "students": ["students", "student", "school", "class"],
    "gift": ["gift", "gifts", "present", "birthday"],
    "ink": ["ink", "fluid", "juicy", "dry"],
    "pen": ["pen", "pens", "marker", "markers"],
    "100": ["100", "count", "variety", "huge set", "large pack", "plenty", "lots of"],
    "plus": ["plus", "extra", "bonus", "additional"],
    "certificated": ["certificated", "safe", "non-toxic", "certification", "sds", "conform"],
    "caliart": ["caliart","brand"],
    "colorless": ["colorless", "blender", "0", "clear"],
    "shuttle": ["shuttle", "shuttle art","brand"],
    "gifts": ["gifts", "gift", "present", "birthday", "christmas"],
    "white": ["white", "highlight", "blender", "light"],
    "120": ["120", "count", "huge", "variety", "selection"],
    "honolulu": ["honolulu", "ohuhu","brand"],
    "colored": ["colored", "color", "colors", "pigment"],
    "pastel": ["pastel", "pale", "light colors", "soft"],
    "black": ["black", "dark", "outline", "liner"],
    "holders": ["holders", "case", "stand", "tray", "base"],
    "262": ["262", "massive", "every color", "giant", "complete"],
    "blending": ["blending", "blend", "mix", "gradient", "seamless"],
    "carrying": ["carrying", "case", "bag", "portable", "travel"],
    "tone": ["tone", "tones", "skin", "shades"],
    "kit": ["kit", "set", "pack", "supplies", "bundle"],
    "illustrations": ["illustrations", "illustration"],
    "girls": ["girls", "girl", "daughter", "granddaughter", "niece"],
    "boys": ["boys", "boy", "son", "grandson", "nephew"],
    "portrait": ["portrait", "faces", "skin", "flesh", "people"],
    "sfaih": ["sfaih","brand"],
    "skin": ["skin", "flesh", "portrait", "tones", "nude"],
    "broad": ["broad", "chisel", "wide", "thick"],
    "professional": ["professional", "pro", "quality", "artist grade"],
    "school": ["school", "class", "project", "student"],
    "base": ["base", "alcohol based"],
    "anime": ["anime", "manga", "comic", "characters"],
    "blendable": ["blendable", "blending", "mix", "seamless"],
    "168": ["168", "count", "set", "massive"],
    "wellokb": ["wellokb","brand"],
    "oahu": ["oahu", "ohuhu","brand"],
    "taotree": ["taotree","brand"],
    "soucolor": ["soucolor","brand"],
    "animation": ["animation", "anime", "cartoon", "characters"],
    "penholder": ["penholder", "base", "stand", "organizer", "tray"],
    "anymark": ["anymark", "brand"],
    "copic": ["copic","brand"],
    "cute": ["cute", "adorable", "kawaii", "lovely", "pretty"],
    "121": ["121", "massive", "every color", "giant", "count", "set"],
    "teen": ["teen", "teens", "teenager", "youth"],
    "aesthetic": ["aesthetic", "beautiful", "vibrant", "pretty"],
    "creators": ["creators", "creator", "artists"],
    "barrel": ["barrel", "handle", "hold", "grip", "shape"],
    "bonus": ["bonus", "extra", "free", "additional", "gift"],
    "series": ["series", "collection", "set"],
    "highlighters": ["highlighters", "highlighting", "neon", "bright"],
    "teens": ["teens", "teenager", "youth", "12-17"],
    "decorations": ["decorations", "decor", "craft", "diy"],
    "memoffice": ["memoffice", "brand"],
    "stuffers": ["stuffers", "fillers", "gift", "stocking"],
    "underlining": ["underlining", "underline", "highlight", "note taking"],
    "halloween": ["halloween", "spooky", "fall", "orange", "black"],
    "highlighters": ["highlighters", "highlighting", "neon", "marker"],
    "highlighter": ["highlighter", "highlighting", "neon", "marker"],
    "bianyo": ["bianyo"],
    "cozy": ["cozy", "comfortable", "warm", "homey"],
}

CLEAN_MAPPING = {str(k).lower(): [str(i).lower() for i in v] for k, v in EXTENDED_MAPPING.items()}

# --- 1. åŸºç¡€åˆ†è¯å‡½æ•° ---
def get_title_keywords(title):
    words = re.findall(r'\b\w{3,}\b', str(title).lower())
    stop_words = {'and', 'the', 'with', 'for', 'based', 'from', 'this', 'that', 'these', 'those'}
    return list(set([w for w in words if w not in stop_words]))

# --- 2. æ ¸å¿ƒåˆ†æé€»è¾‘ ---

def perform_analysis(df, mode="exact"):
    """
    mode: "exact" ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„ top_kws è¿›è¡Œè¯å¯¹è¯åŒ¹é…
    mode: "fuzzy" ä½¿ç”¨ EXTENDED_MAPPING è¿›è¡Œè¯­ä¹‰ä¸›åŒ¹é…
    """
    df['Title'] = df['Title'].fillna('').astype(str).str.lower()
    df['Review Content'] = df['Review Content'].fillna('').astype(str).str.lower()
    
    total_asins = df['ASIN'].nunique()
    asin_level_df = df.groupby('ASIN')['Title'].first().reset_index()
    asin_groups = {asin: group for asin, group in df.groupby('ASIN')}

    if mode == "exact":
        asin_level_df['kw_list'] = asin_level_df['Title'].apply(get_title_keywords)
        all_title_words = [w for ks in asin_level_df['kw_list'] for w in ks]
        target_list = [item[0] for item in Counter(all_title_words).most_common(100)]
    else:
        target_list = list(CLEAN_MAPPING.keys())

    analysis_data = []

    for key_word in target_list:
        # 1. é”å®šæ ‡é¢˜åŒ…å«è¯¥è¯çš„ ASIN
        title_pattern = fr'\b{re.escape(key_word)}\b'
        relevant_asins = asin_level_df[asin_level_df['Title'].str.contains(title_pattern, na=False)]['ASIN'].tolist()
        
        title_mentions = len(relevant_asins)
        if title_mentions == 0: continue
            
        title_penetration = (title_mentions / total_asins) * 100
        
        # 2. é”å®šè¯„è®ºå­é›†
        relevant_reviews_series = pd.concat([asin_groups[a]['Review Content'] for a in relevant_asins])
        specific_total_reviews = len(relevant_reviews_series)

        # 3. ç¡®å®šåŒ¹é…æ¨¡å¼
        if mode == "exact":
            match_pattern = title_pattern
            display_name = key_word
            extra_info = "-"
        else:
            synonyms = CLEAN_MAPPING[key_word]
            match_pattern = r'\b(' + '|'.join([re.escape(s) for s in synonyms]) + r')\b'
            display_name = key_word
            extra_info = ", ".join(synonyms[:3]) + "..."

        # 4. è®¡ç®—æŒ‡æ ‡
        review_mentions = relevant_reviews_series.str.contains(match_pattern, na=False).sum()
        review_echo_rate = (review_mentions / specific_total_reviews * 100) if specific_total_reviews > 0 else 0
        conversion = review_echo_rate / title_penetration if title_penetration > 0 else 0

        analysis_data.append({
            "å…³é”®è¯/å–ç‚¹": display_name,
            "è¯­ä¹‰æ¶µç›–èŒƒå›´": extra_info,
            "æ ‡é¢˜ASINæ•°": title_mentions,
            "æ ‡é¢˜æ¸—é€ç‡ (%)": round(title_penetration, 2),
            "å…³è”è¯„è®ºæ€»æ•°": specific_total_reviews,
            "è¯„è®ºæåŠæ¬¡æ•°": review_mentions,
            "è¯„è®ºå›å£°ç‡ (%)": round(review_echo_rate, 2),
            "å¿ƒæ™ºè½¬åŒ–æ¯”": round(conversion, 2)
        })

    return pd.DataFrame(analysis_data).sort_values("è¯„è®ºå›å£°ç‡ (%)", ascending=False)

# --- 3. å±•ç¤ºå±‚ ---
st.title("ğŸ¯ é…’ç²¾ç¬”å–ç‚¹æ¸—é€çœ‹æ¿ (å…¨æ•ˆåˆä¸€ç‰ˆ)")

uploaded_file = st.file_uploader("ä¸Šä¼ æ•°æ®æ–‡ä»¶ (Excel/CSV)", type=['csv', 'xlsx'])

if uploaded_file:
    df_input = pd.read_csv(uploaded_file) if uploaded_file.name.endswith('.csv') else pd.read_excel(uploaded_file)
    total_a = df_input['ASIN'].nunique()
    total_r = len(df_input)

    st.sidebar.metric("åˆ†æ ASIN æ€»æ•°", total_a)
    st.sidebar.metric("åˆ†æè¯„è®ºæ€»æ¡æ•°", total_r)

    # ä½¿ç”¨æ ‡ç­¾é¡µåŒºåˆ†ä¸¤ç§æ¨¡å¼
    tab1, tab2 = st.tabs(["ğŸ” è¯é¢‘ç²¾ç¡®åŒ¹é… (ç³»ç»Ÿè‡ªåŠ¨å‘ç°)", "ğŸ§¬ è¯­ä¹‰æ¨¡ç³ŠåŒ¹é… (åŸºäºè‡ªå®šä¹‰è¯åº“)"])

    with tab1:
        st.markdown("ğŸ” **é€»è¾‘ï¼š** è‡ªåŠ¨æå–æ ‡é¢˜é«˜é¢‘è¯ï¼Œå¹¶åœ¨è¯„è®ºä¸­å¯»æ‰¾**ä¸€æ¨¡ä¸€æ ·**çš„å•è¯ã€‚")
        res_exact = perform_analysis(df_input, mode="exact")
        st.dataframe(res_exact.style.background_gradient(subset=['è¯„è®ºå›å£°ç‡ (%)', 'å¿ƒæ™ºè½¬åŒ–æ¯”'], cmap='YlGnBu'), use_container_width=True)

    with tab2:
        st.markdown("ğŸ§¬ **é€»è¾‘ï¼š** å½“æ ‡é¢˜å‡ºç°æ ¸å¿ƒè¯æ—¶ï¼Œåœ¨è¯„è®ºä¸­å¯»æ‰¾å…¶**æ‰€æœ‰åŒä¹‰è¯**ï¼ˆå¦‚ï¼šæ ‡é¢˜æœ‰dualï¼Œè¯„è®ºæœ‰doubleä¹Ÿç®—å‘½ä¸­ï¼‰ã€‚")
        res_fuzzy = perform_analysis(df_input, mode="fuzzy")
        st.dataframe(res_fuzzy.style.background_gradient(subset=['è¯„è®ºå›å£°ç‡ (%)', 'å¿ƒæ™ºè½¬åŒ–æ¯”'], cmap='OrRd'), use_container_width=True)
else:
    st.info("è¯·åœ¨ä¸Šæ–¹ä¸Šä¼ æ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
