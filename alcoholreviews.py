import pandas as pd
import streamlit as st
import plotly.express as px
import re
from collections import Counter

# è®¾ç½®é¡µé¢å®½åº¦å’Œæ ‡é¢˜
st.set_page_config(page_title="é…’ç²¾ç¬”å–ç‚¹æ¸—é€çœ‹æ¿", layout="wide")

# --- 1. æå…¶åŸºç¡€çš„åˆ†è¯å‡½æ•° ---
def get_title_keywords(title):
    # \b\w{3,}\b è¡¨ç¤ºåŒ¹é…é•¿åº¦å¤§äºç­‰äº3çš„å•è¯æˆ–æ•°å­—
    words = re.findall(r'\b\w{3,}\b', str(title).lower())
    
    # ä»…ä¿ç•™æœ€åŸºç¡€çš„è¯­æ³•è™šè¯ï¼Œä¸å¹²é¢„ä¸šåŠ¡è¯æ±‡
    stop_words = {'and', 'the', 'with', 'for', 'based', 'from', 'this', 'that', 'these', 'those'}
    
    # æ ‡é¢˜å†…éƒ¨å»é‡ï¼šä¸€ä¸ªæ ‡é¢˜é‡Œå‡ºç°ä¸¤æ¬¡åŒæ ·çš„è¯ï¼Œå¯¹è¯¥ ASIN åªè®°ä¸€æ¬¡
    return list(set([w for w in words if w not in stop_words]))

# --- 2. æ ¸å¿ƒåˆ†æé€»è¾‘ ---
def analyze_market_echo(df):
    # åŸºç¡€åˆ—åæ ¡éªŒ
    required_cols = ['ASIN', 'Title', 'Review Content']
    if not all(col in df.columns for col in required_cols):
        st.error(f"æ•°æ®ç¼ºå¤±å…³é”®åˆ—ï¼Œè¯·ç¡®ä¿æ–‡ä»¶åŒ…å«: {required_cols}")
        return pd.DataFrame(), 0, 0

    # é¢„å¤„ç†ç¼ºå¤±å€¼
    df['Title'] = df['Title'].fillna('')
    df['Review Content'] = df['Review Content'].fillna('')
    
    total_asins = df['ASIN'].nunique()
    total_reviews = len(df)

    # --- A. æ ‡é¢˜ç»Ÿè®¡ (ASINå»é‡) ---
    # æ¯ä¸ª ASIN åªå–ç¬¬ä¸€æ¡æ ‡é¢˜è®°å½•ï¼Œé˜²æ­¢è¯„è®ºè¡Œæ•°å¹²æ‰°æ ‡é¢˜è¯é¢‘
    asin_level_df = df.groupby('ASIN')['Title'].first().reset_index()
    asin_level_df['kw_list'] = asin_level_df['Title'].apply(get_title_keywords)
    
    all_title_words = []
    for ks in asin_level_df['kw_list']:
        all_title_words.extend(ks)
    
    kw_counts = Counter(all_title_words)
    # å–æ ‡é¢˜ä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„å‰ 50 ä¸ªå…³é”®è¯
    top_kws = [item[0] for item in kw_counts.most_common(50)]

    # --- B. è¯„è®ºç»Ÿè®¡ (æŒ‰è¡Œè®¡æ•°) ---
    analysis_data = []
    for kw in top_kws:
        # æ ‡é¢˜ç«¯æŒ‡æ ‡
        title_mentions = kw_counts[kw]
        title_penetration = (title_mentions / total_asins) * 100
        
        # è¯„è®ºç«¯æŒ‡æ ‡ (ç²¾ç¡®å…¨è¯åŒ¹é…)
        pattern = fr'\b{kw}\b'
        review_mentions = df['Review Content'].str.contains(pattern, case=False, na=False).sum()
        review_echo_rate = (review_mentions / total_reviews) * 100
        
        analysis_data.append({
            "å…³é”®è¯": kw,
            "æ ‡é¢˜æåŠæ¬¡æ•° (ASINæ•°)": title_mentions,
            "æ ‡é¢˜æ¸—é€ç‡ (%)": round(title_penetration, 2),
            "è¯„è®ºæåŠæ¬¡æ•° (è¡Œæ•°)": review_mentions,
            "è¯„è®ºå›å£°ç‡ (%)": round(review_echo_rate, 2)
        })

    result_df = pd.DataFrame(analysis_data)
    # è®¡ç®—è½¬åŒ–æ•ˆç‡ï¼šå›å£°ç‡ / æ¸—é€ç‡
    result_df['å¿ƒæ™ºè½¬åŒ–æ¯”'] = (result_df['è¯„è®ºå›å£°ç‡ (%)'] / result_df['æ ‡é¢˜æ¸—é€ç‡ (%)']).round(2)
    
    return result_df, total_asins, total_reviews

# --- 3. Streamlit å±•ç¤ºå±‚ ---
st.title("ğŸ¯ å–ç‚¹å›å£°åˆ†æçœ‹æ¿")
st.markdown("""
è¯¥å·¥å…·åˆ†æ**å•†å®¶å®£ä¼ è¯ï¼ˆæ ‡é¢˜ï¼‰**ä¸**ç”¨æˆ·å¤è¿°è¯ï¼ˆè¯„è®ºï¼‰**çš„é‡åˆåº¦ï¼š
* **æ ‡é¢˜æ¸—é€ç‡**: è¯¥å–ç‚¹åœ¨å¤šå°‘æ¯”ä¾‹çš„å•†å“æ ‡é¢˜ä¸­å‡ºç°äº†ã€‚
* **è¯„è®ºå›å£°ç‡**: è¯¥å–ç‚¹åœ¨å¤šå°‘æ¯”ä¾‹çš„ç”¨æˆ·è¯„è®ºä¸­è¢«æåˆ°äº†ã€‚
""")

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("ä¸Šä¼ é…’ç²¾ç¬”æ•°æ® (CSV æˆ– Excel)", type=['csv', 'xlsx'])

if uploaded_file:
    # è¯»å–æ•°æ®
    if uploaded_file.name.endswith('.csv'):
        df_input = pd.read_csv(uploaded_file)
    else:
        df_input = pd.read_excel(uploaded_file)
    
    # æ‰§è¡Œåˆ†æ
    res_df, total_a, total_r = analyze_market_echo(df_input)
    
    if not res_df.empty:
        # æ•°æ®å¡ç‰‡å±•ç¤ºç»Ÿè®¡åŸºæ•°
        col_m1, col_m2 = st.columns(2)
        col_m1.metric("åˆ†æ ASIN æ€»æ•°", total_a)
        col_m2.metric("åˆ†æè¯„è®ºæ€»æ¡æ•°", total_r)

        st.divider()

        # æ•°æ®è¡¨æ ¼å±•ç¤º
        st.subheader("ğŸ“Š å…³é”®è¯æŒ‡æ ‡æ˜ç»†")
        # é»˜è®¤æŒ‰è¯„è®ºå›å£°ç‡æ’åº
        res_df = res_df.sort_values("è¯„è®ºå›å£°ç‡ (%)", ascending=False)
        st.dataframe(
            res_df.style.background_gradient(subset=['è¯„è®ºå›å£°ç‡ (%)', 'æ ‡é¢˜æ¸—é€ç‡ (%)'], cmap='Blues'),
            use_container_width=True
        )

        # å¯è§†åŒ–å›¾è¡¨
        st.subheader("ğŸ’¡ å¸‚åœºæ¸—é€ vs ç”¨æˆ·æ„ŸçŸ¥ è±¡é™å›¾")
        fig = px.scatter(
            res_df, 
            x="æ ‡é¢˜æ¸—é€ç‡ (%)", 
            y="è¯„è®ºå›å£°ç‡ (%)",
            size="æ ‡é¢˜æåŠæ¬¡æ•° (ASINæ•°)",
            color="å¿ƒæ™ºè½¬åŒ–æ¯”",
            text="å…³é”®è¯",
            hover_name="å…³é”®è¯",
            labels={"å¿ƒæ™ºè½¬åŒ–æ¯”": "è½¬åŒ–æ•ˆç‡ (å›å£°/æ¸—é€)"},
            title="æ¨ªè½´: å¸‚åœºå®£ä¼ å¼ºåº¦ | çºµè½´: ç”¨æˆ·åé¦ˆå¼ºåº¦",
            height=600
        )
        fig.update_traces(textposition='top center')
        # æ·»åŠ  1:1 å‚è€ƒå¯¹è§’çº¿
        max_val = max(res_df["æ ‡é¢˜æ¸—é€ç‡ (%)"].max(), res_df["è¯„è®ºå›å£°ç‡ (%)"].max())
        fig.add_shape(type="line", x0=0, y0=0, x1=max_val, y1=max_val, 
                      line=dict(color="Gray", dash="dash"))
        
        st.plotly_chart(fig, use_container_width=True)

        st.info("**è±¡é™è§£è¯»ï¼š**\n\n1. **å·¦ä¸Šè§’ (é«˜å›å£°/ä½æ¸—é€)**ï¼šé»‘é©¬éœ€æ±‚ï¼å•†å®¶æå¾—å°‘ï¼Œç”¨æˆ·å´å¾ˆåœ¨æ„ï¼Œåº”åŠ å¼ºå®£ä¼ ã€‚\n2. **å³ä¸‹è§’ (ä½å›å£°/é«˜æ¸—é€)**ï¼šæ— æ•ˆå †ç Œã€‚å•†å®¶å†™å¾—å¤šï¼Œç”¨æˆ·ä¸ä¹°è´¦ï¼Œå»ºè®®ä¼˜åŒ–æ ‡é¢˜ã€‚")
else:
    st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨ä¾§è¾¹æ æˆ–ä¸Šæ–¹ä¸Šä¼ æ•°æ®æ–‡ä»¶ã€‚")
