import pandas as pd
import streamlit as st
import re
from collections import Counter

# è®¾ç½®é¡µé¢å®½åº¦å’Œæ ‡é¢˜
st.set_page_config(page_title="é…’ç²¾ç¬”å–ç‚¹æ¸—é€çœ‹æ¿", layout="wide")

# --- 1. æå…¶åŸºç¡€çš„åˆ†è¯å‡½æ•° ---
def get_title_keywords(title):
    # \b\w{3,}\b åŒ¹é…é•¿åº¦å¤§äºç­‰äº3çš„å•è¯æˆ–æ•°å­—
    words = re.findall(r'\b\w{3,}\b', str(title).lower())
    
    # åŸºç¡€è¯­æ³•è™šè¯
    stop_words = {'and', 'the', 'with', 'for', 'based', 'from', 'this', 'that', 'these', 'those'}
    
    # æ ‡é¢˜å†…éƒ¨å»é‡
    return list(set([w for w in words if w not in stop_words]))

# --- 2. æ ¸å¿ƒåˆ†æé€»è¾‘ ---
def analyze_market_echo(df):
    # åŸºç¡€åˆ—åæ ¡éªŒ
    required_cols = ['ASIN', 'Title', 'Review Content']
    if not all(col in df.columns for col in required_cols):
        st.error(f"æ•°æ®ç¼ºå¤±å…³é”®åˆ—ï¼Œè¯·ç¡®ä¿æ–‡ä»¶åŒ…å«: {required_cols}")
        return pd.DataFrame(), 0, 0

    # é¢„å¤„ç†ç¼ºå¤±å€¼
    df['Title'] = df['Title'].fillna('')
    df['Review Content'] = df['Review Content'].fillna('')
    
    total_asins = df['ASIN'].nunique()
    total_reviews = len(df)

    # --- A. æ ‡é¢˜ç«¯ç»Ÿè®¡ (æŒ‰ ASIN æå–å…³é”®è¯) ---
    asin_level_df = df.groupby('ASIN')['Title'].first().reset_index()
    asin_level_df['kw_list'] = asin_level_df['Title'].apply(get_title_keywords)
    
    all_title_words = []
    for ks in asin_level_df['kw_list']:
        all_title_words.extend(ks)
    
    kw_counts = Counter(all_title_words)
    # å–æ ‡é¢˜ä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„å‰ 100 ä¸ªå…³é”®è¯ä½œä¸ºåˆ†æå¯¹è±¡
    top_kws = [item[0] for item in kw_counts.most_common(100)]

    # --- B. æ ¸å¿ƒåˆ†æå¾ªç¯ (ç²¾ç¡®åŒ¹é…åˆ†æ) ---
    analysis_data = []
    
    for kw in top_kws:
        # 1. æ‰¾åˆ°æ ‡é¢˜é‡ŒåŒ…å«è¯¥å…³é”®è¯çš„ ASIN åˆ—è¡¨
        # ä½¿ç”¨ \b ç¡®ä¿ç²¾ç¡®åŒ¹é…å•è¯
        pattern = fr'\b{re.escape(kw)}\b'
        
        # è¿™é‡Œçš„ boolean mask ç”¨äºæ‰¾å‡ºå“ªäº› ASIN çš„æ ‡é¢˜å«æ­¤è¯
        has_kw_mask = asin_level_df['Title'].str.contains(pattern, case=False, na=False)
        relevant_asins = asin_level_df[has_kw_mask]['ASIN'].unique()
        
        title_mentions = len(relevant_asins) 
        title_penetration = (title_mentions / total_asins) * 100
        
        # 2. é’ˆå¯¹è¿™äº› ASIN çš„è¯„è®ºè¿›è¡Œåˆ†æ
        if title_mentions > 0:
            # ç­›é€‰å‡ºå±äºè¿™äº› ASIN çš„æ‰€æœ‰è¯„è®ºè¡Œ
            relevant_reviews_df = df[df['ASIN'].isin(relevant_asins)]
            specific_total_reviews = len(relevant_reviews_df) # å±€éƒ¨è¯„è®ºæ€»æ•° (åˆ†æ¯)
            
            # åœ¨è¿™äº›è¯„è®ºä¸­ï¼Œæåˆ°è¯¥å…³é”®è¯çš„æ¬¡æ•° (åˆ†å­)
            review_mentions = relevant_reviews_df['Review Content'].str.contains(pattern, case=False, na=False).sum()
            
            # è®¡ç®—å›å£°ç‡ï¼šæåˆ°çš„è¯„è®ºæ•° / è¯¥å–ç‚¹å…³è”çš„æ€»è¯„è®ºæ•°
            review_echo_rate = (review_mentions / specific_total_reviews) * 100
        else:
            review_mentions = 0
            review_echo_rate = 0
            specific_total_reviews = 0

        # è®¡ç®—å¿ƒæ™ºè½¬åŒ–æ¯” (åˆ†æ¯ä¿æŠ¤)
        conversion_ratio = round(review_echo_rate / title_penetration, 2) if title_penetration > 0 else 0

        analysis_data.append({
            "å…³é”®è¯": kw,
            "æ ‡é¢˜æåŠASINæ•°": title_mentions,
            "æ ‡é¢˜æ¸—é€ç‡ (%)": round(title_penetration, 2),
            "å…³è”è¯„è®ºæ€»æ•° (åˆ†æ¯)": specific_total_reviews,
            "è¯„è®ºæåŠæ¬¡æ•° (åˆ†å­)": review_mentions,
            "è¯„è®ºå›å£°ç‡ (%)": round(review_echo_rate, 2),
            "å¿ƒæ™ºè½¬åŒ–æ¯”": conversion_ratio
        })

    result_df = pd.DataFrame(analysis_data)
    return result_df, total_asins, total_reviews

# --- 3. Streamlit å±•ç¤ºå±‚ ---
st.title("ğŸ¯ å–ç‚¹å›å£°åˆ†æçœ‹æ¿ (ç²¾ç¡®åŒ¹é…ç‰ˆ)")
st.markdown("""
é€šè¿‡å¯¹æ¯” **å•†å®¶å®£ä¼ ï¼ˆæ ‡é¢˜å…³é”®è¯ï¼‰** ä¸ **ç”¨æˆ·å¤è¿°ï¼ˆè¯„è®ºå…³é”®è¯ï¼‰**ï¼Œè¯†åˆ«çœŸå®çš„å–ç‚¹å“åº”ã€‚
- **æ ‡é¢˜æ¸—é€ç‡**: å¸‚åœºä¸Šæœ‰å¤šå¤§æ¯”ä¾‹çš„ ASIN åœ¨æ ‡é¢˜é‡Œæåˆ°äº†è¿™ä¸ªè¯ã€‚
- **è¯„è®ºå›å£°ç‡**: åœ¨**æåˆ°äº†è¯¥è¯çš„å•†å“**ä¸­ï¼Œæœ‰å¤šå¤§æ¯”ä¾‹çš„è¯„è®ºä¹Ÿæåˆ°äº†è¿™ä¸ªè¯ã€‚
""")

uploaded_file = st.file_uploader("ä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶ (Excel æˆ– CSV)", type=['csv', 'xlsx'])

if uploaded_file:
    if uploaded_file.name.endswith('.csv'):
        df_input = pd.read_csv(uploaded_file)
    else:
        df_input = pd.read_excel(uploaded_file)
    
    res_df, total_a, total_r = analyze_market_echo(df_input)
    
    if not res_df.empty:
        m1, m2 = st.columns(2)
        m1.metric("åˆ†æ ASIN æ€»æ•°", total_a)
        m2.metric("åˆ†æè¯„è®ºæ€»æ¡æ•°", total_r)

        st.divider()

        st.subheader("ğŸ“Š å…³é”®è¯å–ç‚¹è½¬åŒ–æ¸…å•")
        
        # é»˜è®¤æŒ‰è¯„è®ºå›å£°ç‡æ’åº
        res_df = res_df.sort_values("è¯„è®ºå›å£°ç‡ (%)", ascending=False)
        
        # èƒŒæ™¯æ¸å˜ç¾åŒ–
        styled_df = res_df.style.background_gradient(
            subset=['æ ‡é¢˜æ¸—é€ç‡ (%)', 'è¯„è®ºå›å£°ç‡ (%)', 'å¿ƒæ™ºè½¬åŒ–æ¯”'], 
            cmap='GnBu'
        )
        
        st.dataframe(styled_df, use_container_width=True)

else:
    st.warning("ğŸ‘ˆ è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶è¿›è¡Œåˆ†æã€‚")
